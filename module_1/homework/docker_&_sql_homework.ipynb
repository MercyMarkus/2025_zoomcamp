{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22889a1-a32c-4596-8c5d-89364f9bef18",
   "metadata": {},
   "source": [
    "# Module 1 Homework: Docker & SQL\n",
    "\n",
    "In this homework we'll prepare the environment and practice Docker and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f707a-d622-4c7c-a318-2339c763b068",
   "metadata": {},
   "source": [
    "## Question 1. Understanding docker first run \n",
    "\n",
    "Run docker with the `python:3.12.8` image in an interactive mode, use the entrypoint `bash`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaa22694-dbdb-484b-8801-2281874abb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0b7bd244d174afaa16069a17674c270de3d247ed7f53a63e1491bf27e054b73\n",
      "CONTAINER ID   IMAGE           COMMAND   CREATED        STATUS                  PORTS     NAMES\n",
      "b0b7bd244d17   python:3.12.8   \"bash\"    1 second ago   Up Less than a second             happy_bell\n"
     ]
    }
   ],
   "source": [
    "!docker run -it -d --entrypoint=bash python:3.12.8\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e37797a5-8ea2-477e-a143-3ce371fd8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.3.1 from /usr/local/lib/python3.12/site-packages/pip (python 3.12)\n"
     ]
    }
   ],
   "source": [
    "!docker exec b0b7bd244d17 pip --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3589c-555a-40d0-8d9d-a9c2aac1320c",
   "metadata": {},
   "source": [
    "What's the version of `pip` in the image?\n",
    "\n",
    "- [x] 24.3.1\n",
    "- [ ] 24.2.1\n",
    "- [ ] 23.3.1\n",
    "- [ ] 23.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5228a-581a-444b-a4be-46e7ebb59717",
   "metadata": {},
   "source": [
    "## Question 2. Understanding Docker networking and docker-compose\n",
    "\n",
    "Given the following `docker-compose.yaml`, what is the `hostname` and `port` that **pgadmin** should use to connect to the postgres database?\n",
    "- [ ] postgres:5433\n",
    "- [ ] localhost:5432\n",
    "- [ ] db:5433\n",
    "- [ ] postgres:5432\n",
    "- [x] db:5432"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3a619-871c-4b69-8673-2f34876246f8",
   "metadata": {},
   "source": [
    "##  Prepare Postgres\n",
    "\n",
    "Run Postgres and load data as shown in the videos\n",
    "We'll use the green taxi trips from October 2019:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\n",
    "```\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
    "```\n",
    "\n",
    "Download this data and put it into Postgres.\n",
    "\n",
    "You can use the code from the course. It's up to you whether\n",
    "you want to use Jupyter or a python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8f11c7df-5a77-4a9c-b4f6-8b22b8e86986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cdf954a-443f-4cd7-a07e-b785a309e726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Downloading 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz' ...\n",
      "HTTP response 302  [https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz]\n",
      "Adding URL: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155017Z&X-Amz-Expires=300&X-Amz-Signature=150e0ebec8bc6777ba9a4a4a583874c15db1c1e733fcde0e5ac310b1d8bc3b1e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "[0] Downloading 'https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155017Z&X-Amz-Expires=300&X-Amz-Signature=150e0ebec8bc6777ba9a4a4a583874c15db1c1e733fcde0e5ac310b1d8bc3b1e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream' ...\n",
      "Saving 'output.csv.gz'\n",
      "HTTP response 200  [https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155017Z&X-Amz-Expires=300&X-Amz-Signature=150e0ebec8bc6777ba9a4a4a583874c15db1c1e733fcde0e5ac310b1d8bc3b1e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream]\n",
      "[0] Downloading 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv' ...\n",
      "HTTP response 302  [https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv]\n",
      "Adding URL: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155024Z&X-Amz-Expires=300&X-Amz-Signature=5b8cd6354c105f7f314ef5815e46c8b3d50e4a9014a004c3337ce664f3f234f6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "[0] Downloading 'https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155024Z&X-Amz-Expires=300&X-Amz-Signature=5b8cd6354c105f7f314ef5815e46c8b3d50e4a9014a004c3337ce664f3f234f6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream' ...\n",
      "Saving 'output.csv'\n",
      "HTTP response 200  [https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250123%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250123T155024Z&X-Amz-Expires=300&X-Amz-Signature=5b8cd6354c105f7f314ef5815e46c8b3d50e4a9014a004c3337ce664f3f234f6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream]\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz', \n",
    "       'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv']\n",
    "\n",
    "for url in urls:\n",
    "        # Use the correct file extension\n",
    "    if url.endswith('.csv.gz'):\n",
    "        csv_name = 'output.csv.gz'\n",
    "    else:\n",
    "        csv_name = 'output.csv'\n",
    "    os.system(f\"wget {url} -O {csv_name}\")\n",
    "    \n",
    "engine = create_engine(f'postgresql://postgres:postgres@localhost:5433/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "653ba992-729c-499d-b207-ed079c0f61b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fd989d47a40>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7542d6e0-42dd-4c22-a46f-3273155fd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk in 6.892 seconds\n",
      "Inserted another chunk in 6.599 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_397275/1552648659.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_chunk = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk in 5.670 seconds\n",
      "Inserted another chunk in 5.290 seconds\n",
      "Finished ingesting data into the postgreSQL database\n"
     ]
    }
   ],
   "source": [
    "df_iter = pd.read_csv('output.csv.gz', iterator=True, chunksize=100000)\n",
    "table_name = 'green_tripdata_2019'\n",
    "\n",
    "df = next(df_iter)\n",
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "\n",
    "df.head(n=0).to_sql(name=table_name, con=engine, if_exists='replace')\n",
    "\n",
    "df.to_sql(name=table_name, con=engine, if_exists=\"append\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        start_time = time()\n",
    "        data_chunk = next(df_iter)\n",
    "\n",
    "        data_chunk.lpep_pickup_datetime = pd.to_datetime(data_chunk.lpep_pickup_datetime)\n",
    "        data_chunk.lpep_dropoff_datetime = pd.to_datetime(data_chunk.lpep_dropoff_datetime)\n",
    "\n",
    "        data_chunk.to_sql(name=table_name, con=engine, if_exists=\"append\")\n",
    "        end_time = time()\n",
    "\n",
    "        print(\"Inserted another chunk in %.3f seconds\" % (end_time - start_time))\n",
    "    except StopIteration:\n",
    "        print(\"Finished ingesting data into the postgreSQL database\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "270a65cb-844f-4e9a-b5a9-85dbdab15a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ingesting data into the postgreSQL database\n"
     ]
    }
   ],
   "source": [
    "df_iter = pd.read_csv('output.csv', iterator=True, chunksize=100000)\n",
    "table_name = 'taxi_zone_lookup'\n",
    "\n",
    "df = next(df_iter)\n",
    "\n",
    "df.head(n=0).to_sql(name=table_name, con=engine, if_exists='replace')\n",
    "\n",
    "df.to_sql(name=table_name, con=engine, if_exists=\"append\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        start_time = time()\n",
    "        data_chunk = next(df_iter)\n",
    "\n",
    "        data_chunk.to_sql(name=table_name, con=engine, if_exists=\"append\")\n",
    "        end_time = time()\n",
    "\n",
    "        print(\"Inserted another chunk in %.3f seconds\" % (end_time - start_time))\n",
    "    except StopIteration:\n",
    "        print(\"Finished ingesting data into the postgreSQL database\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c63e6c-856b-4327-b63c-3d577d455e67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 3. Trip Segmentation Count\n",
    "\n",
    "During the period of October 1st 2019 (inclusive) and November 1st 2019 (exclusive), how many trips, **respectively**, happened:\n",
    "1. Up to 1 mile\n",
    "2. In between 1 (exclusive) and 3 miles (inclusive),\n",
    "3. In between 3 (exclusive) and 7 miles (inclusive),\n",
    "4. In between 7 (exclusive) and 10 miles (inclusive),\n",
    "5. Over 10 miles \n",
    "\n",
    "Answers:\n",
    "\n",
    "- [ ] 104,802;  197,670;  110,612;  27,831;  35,281\n",
    "- [x] 104,802;  198,924;  109,603;  27,678;  35,189\n",
    "- [ ] 104,793;  201,407;  110,612;  27,831;  35,281\n",
    "- [ ] 104,793;  202,661;  109,603;  27,678;  35,189\n",
    "- [ ] 104,838;  199,013;  109,645;  27,688;  35,202\n",
    "\n",
    "\n",
    "### Queries\n",
    "1. ```SQL\n",
    "    SELECT\n",
    "    COUNT(*) as total_trips\n",
    "    FROM\n",
    "    \tpublic.green_tripdata_2019\n",
    "    WHERE\n",
    "    \tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "    \tand\n",
    "    \tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "    \tand trip_distance <= 1\n",
    "        \n",
    "2. ```SQL\n",
    "    SELECT\n",
    "    COUNT(*) as total_trips\n",
    "    FROM\n",
    "    \tpublic.green_tripdata_2019\n",
    "    WHERE\n",
    "    \tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "    \tand\n",
    "    \tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "    \tand trip_distance > 1\n",
    "    \tand trip_distance <= 3\n",
    "        \n",
    "3. ```SQL\n",
    "    SELECT\n",
    "    COUNT(*) as total_trips\n",
    "    FROM\n",
    "    \tpublic.green_tripdata_2019\n",
    "    WHERE\n",
    "    \tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "    \tand\n",
    "    \tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "    \tand trip_distance > 3\n",
    "    \tand trip_distance <= 7\n",
    "        \n",
    "4. ```SQL\n",
    "    SELECT\n",
    "    COUNT(*) as total_trips\n",
    "    FROM\n",
    "    \tpublic.green_tripdata_2019\n",
    "    WHERE\n",
    "    \tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "    \tand\n",
    "    \tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "    \tand trip_distance > 7\n",
    "    \tand trip_distance <= 10\n",
    "\n",
    "5. ```SQL\n",
    "    SELECT\n",
    "    COUNT(*) as total_trips\n",
    "    FROM\n",
    "    \tpublic.green_tripdata_2019\n",
    "    WHERE\n",
    "    \tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "    \tand\n",
    "    \tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "    \tand trip_distance > 10\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96322c-375b-4037-9b1c-57a42f0836f0",
   "metadata": {},
   "source": [
    "## Question 4. Longest trip for each day\n",
    "\n",
    "Which was the pick up day with the longest trip distance?\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "Tip: For every day, we only care about one single trip with the longest distance. \n",
    "\n",
    "- [ ] 2019-10-11\n",
    "- [ ] 2019-10-24\n",
    "- [ ] 2019-10-26\n",
    "- [x] 2019-10-31\n",
    "\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    CAST(lpep_pickup_datetime AS DATE) AS \"day\",\n",
    "    MAX(trip_distance) AS \"max\"\n",
    "FROM \n",
    "    public.green_tripdata_2019\n",
    "GROUP BY\n",
    "    CAST(lpep_pickup_datetime AS DATE)\n",
    "ORDER BY\n",
    "    \"max\" DESC\n",
    "LIMIT 100;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ad3fc-fc8c-47eb-80c8-39af0d125c44",
   "metadata": {},
   "source": [
    "## Question 5. Three biggest pickup zones\n",
    "\n",
    "Which were the top pickup locations with over 13,000 in\n",
    "`total_amount` (across all trips) for 2019-10-18?\n",
    "\n",
    "Consider only `lpep_pickup_datetime` when filtering by date.\n",
    " \n",
    "- [x] East Harlem North, East Harlem South, Morningside Heights\n",
    "- [ ] East Harlem North, Morningside Heights\n",
    "- [ ] Morningside Heights, Astoria Park, East Harlem South\n",
    "- [ ] Bedford, East Harlem North, Astoria Park\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    zpu.\"Zone\" AS \"pickup_loc\",\n",
    "\tSUM(t.total_amount) as \"total_amount\"\n",
    "FROM \n",
    "    green_tripdata_2019 t,\n",
    "    taxi_zone_lookup zpu\n",
    "WHERE\n",
    "    t.\"PULocationID\" = zpu.\"LocationID\"\n",
    "\tAND\n",
    "lpep_pickup_datetime >= '2019-10-18' and lpep_pickup_datetime < '2019-10-19'\n",
    "GROUP BY \"pickup_loc\"\n",
    "ORDER BY 2 DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11726cd4-e2fe-4f03-b8f3-287545ed315a",
   "metadata": {},
   "source": [
    "## Question 6. Largest tip\n",
    "\n",
    "For the passengers picked up in October 2019 in the zone\n",
    "named \"East Harlem North\" which was the drop off zone that had\n",
    "the largest tip?\n",
    "\n",
    "Note: it's `tip` , not `trip`\n",
    "\n",
    "We need the name of the zone, not the ID.\n",
    "\n",
    "- [ ] Yorkville West\n",
    "- [x] JFK Airport\n",
    "- [ ] East Harlem North\n",
    "- [ ] East Harlem South\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    zdo.\"Zone\" AS \"dropff_loc\",\n",
    "\tMAX(t.\"tip_amount\")\n",
    "FROM \n",
    "    green_tripdata_2019 t,\n",
    "    taxi_zone_lookup zpu,\n",
    "    taxi_zone_lookup zdo\n",
    "WHERE\n",
    "    t.\"PULocationID\" = zpu.\"LocationID\"\n",
    "    AND t.\"DOLocationID\" = zdo.\"LocationID\"\n",
    "\tAND\n",
    "\tlpep_pickup_datetime >= '2019-10-01' and lpep_pickup_datetime < '2019-11-01' \n",
    "\tand\n",
    "\tlpep_dropoff_datetime >= '2019-10-01'and lpep_dropoff_datetime < '2019-11-01'\n",
    "\tAND zpu.\"Zone\" = 'East Harlem North'\n",
    "GROUP BY \"dropff_loc\"\n",
    "ORDER BY 2 DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a1359-c9b7-4564-a7b4-286b8f58d4cc",
   "metadata": {},
   "source": [
    "## Terraform\n",
    "\n",
    "In this section homework we'll prepare the environment by creating resources in GCP with Terraform.\n",
    "\n",
    "In your VM on GCP/Laptop/GitHub Codespace install Terraform. \n",
    "Copy the files from the course repo\n",
    "[here](../../../01-docker-terraform/1_terraform_gcp/terraform) to your VM/Laptop/GitHub Codespace.\n",
    "\n",
    "Modify the files as necessary to create a GCP Bucket and Big Query Dataset.\n",
    "\n",
    "\n",
    "## Question 7. Terraform Workflow\n",
    "\n",
    "Which of the following sequences, **respectively**, describes the workflow for: \n",
    "1. Downloading the provider plugins and setting up backend,\n",
    "2. Generating proposed changes and auto-executing the plan\n",
    "3. Remove all resources managed by terraform`\n",
    "\n",
    "Answers:\n",
    "- [ ] terraform import, terraform apply -y, terraform destroy\n",
    "- [ ] teraform init, terraform plan -auto-apply, terraform rm\n",
    "- [ ] terraform init, terraform run -auto-approve, terraform destroy\n",
    "- [x] terraform init, terraform apply -auto-approve, terraform destroy\n",
    "- [ ] terraform import, terraform apply -y, terraform rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12cea0-7102-4925-b69b-245cf4a7ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
